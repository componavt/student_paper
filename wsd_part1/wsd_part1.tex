\documentclass{article}

\usepackage{cmap} % чтобы работал поиск по PDF

\usepackage{caption}  %-  вставить в krctran перед описанием подписей caption (\renewcommand\@makecaption)
\usepackage{subcaption} % float figures side by side}  -  вставить в krctran перед описанием подписей caption (\renewcommand\@makecaption)
\usepackage{krctran_modified}
%\usepackage[utf8]{inputenc} % закомментировать в krctran.sty: \RequirePackage[cp1251]{inputenc}
\usepackage[pdftex]{graphicx} % закомментировать в krctran.sty

\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{algorithm2e}
\usepackage{float}
\usepackage{wrapfig}
%\usepackage[dvips]{graphicx}
\graphicspath{ {./pictures/} }

\begin{document}

\procname{Труды Карельского научного центра РАН\\ \No 0. 2015. С.~1--28}
\udk{УДК 81.32}

\rustitle{Обзор методов и алгоритмов разрешения \newline лексической многозначности: Введение}
\engtitle{A review of word-sense disambiguation methods and algorithms: Introduction}

\rusauthor{Т.~В.~Каушинис$^2$,  А.~Н.~Кириллов$^1$,  Н.~И.~Коржицкий$^2$, А.~А.~Крижановский$^1$, А.~В.~Пилинович$^2$, И.~А.~Сихонина$^2$,  А.~М.~Спиркова$^2$, В.~Г.~Старкова$^1$, Т.~В.~Степкина$^2$, С.~С.~Ткач$^2$, Ю.~В.~Чиркова$^1$, А.~Л.~Чухарев$^1$,  Д.~С.~Шорец$^2$,  Д.~Ю.~Янкевич$^2$, Е.~А.~Ярышкина$^2$}
\engauthor{T.~V.~Kaushinis$^2$, A.~N.~Kirillov$^1$, N.~I.~Korzhitsky$^2$, A.~A.~Krizhanovsky$^1$, A.~V.~Pilinovich$^2$, I.~A.~Sikhonina$^2$, A.~M.~Spirkova$^2$, V.~G.~Starkova$^1$, T.~V.~Stepkina$^2$, S.~S.~Tkach$^2$, J.~V.~Chirkova$^1$, A.~L.~Chuharev$^1$, D.~S.~Shorets$^2$, D.~Y.~Yankevich$^2$, E.~A.~Yaryshkina$^2$}

\organization{$^1$Институт прикладных математических исследований Карельского научного центра РАН \\
$^2$Петрозаводский Государственный Университет}

\rusabstract{Разрешение лексической многозначности~(WSD) --- это задача выбора между разными значениями 
слов и словосочетаний в словаре в зависимости от контекста. 
В статье представлен краткий обзор методов и алгоритмов разрешения лексической многозначности. 
Эти методы используют различный математический и алгоритмический аппарат для решения WSD-задачи: нейронные сети, 
адаптивные алгоритмы улучшения точности обучения (AdaBoost), 
построение лексических цепочек, 
методы на основе применения теоремы Байеса 
и методы кластеризации контекстных векторов и семантически близких слов. 
Завершает работу сравнение разных алгоритмов решения WSD-задачи. 
Статья распространяется на правах свободной лицензии “CC Attribution”.
}
\engabstract{The word-sense disambiguation  task is a classification task, where the goal is to predict the meaning of words and phrases with the help of surrounding text. The purpose of this short review is to acquaint the reader with the general directions of word-sense disambiguation methods and algorithms. 
These approaches include the following groups of methods: 
neural network, 
machine learning meta-algorithms (AdaBoost), 
lexical chain computation, 
methods based on Bayes' theorem, 
context clustering and words clustering algorithms. 
The experimental comparison of different algorithms concludes this review.
This paper is licensed under the CC Attribution license.}

\ruskeywords{разрешение лексической многозначности, нейронная сеть, бустинг, лексическая цепочка, наивный байесовский классификатор, байесовская сеть, сочетаемостные ограничения, различение значений слов.}
\engkeywords{word-sense disambiguation, neural network, boosting, lexical chain, naive Bayes classifier, Bayesian network, selectional preferences, word-sense discrimination.}

\maketitle

\begin{articletext}
\section{Введение}
В статье представлен обзор методов и алгоритмов разрешения лексической многозначности (word-sense disambiguation или WSD). Верный выбор в словаре одного из значений многозначного слова или фразы в зависимости от контекста является успешным результатом решения WSD-задачи.

Приведем несколько примеров употребления слов <<коса>> и <<косой>>, найденных с помощью Национального корпуса русского языка (http://ruscorpora.ru) по запросу <<коса>>:

\begin{enumerate}
\item Поп сам в первой \textit{\underline{косе}} идет, но прихожане не торопятся, смотрят на солнышко и часа через полтора уже намекают, что обедать пора. {\footnotesize[\textit{М. Е. Салтыков-Щедрин. Мелочи жизни (1886-1887)}]}
\item Но работа даже и после этого идет все вялее и вялее; некоторые и \textit{\underline{косы}} побросали. {\footnotesize[\textit{М. Е. Салтыков-Щедрин. Мелочи жизни (1886-1887)}]}
\item В особенности жестоко было крепостное право относительно дворовых людей: даже волосы крепостных девок эксплуатировали, продавая их \textit{\underline{косы}} парикмахерам. {\footnotesize[\textit{М. Е. Салтыков-Щедрин. Мелочи жизни (1886-1887)}]}
\item Это одинокая скала, соединяющаяся с материком намывной \textit{\underline{косой}} из песка и гальки. {\footnotesize[\textit{В. К. Арсеньев, «По Уссурийскому краю», 1917 г.}]}
\item Первая черепашка подскочила к гвардейцу и воткнула ему в спину сверкающий \textit{\underline{косой}} меч. {\footnotesize[\textit{Виктор Пелевин. S.N.U.F.F, 2011}]}
\end{enumerate}

Первые четыре примера дают три разных значения существительного <<коса>>: ряд косарей, сельскохозяйственное орудие, заплетенные волосы, протяженная речная отмель. Последний пример содержит прилагательное <<косой>>, совпадающее с одной из форм существительного <<коса>>. Все эти значения и часть речи читатель легко определяет по контексту. 

Именно многозначность слов, их неоднозначность и зависимость значений слов от контекста являются причиной возникновения такой задачи и одновременно обуславливают сложность ее решения. Уверенное решение WSD-задачи необходимо во многих приложениях, связанных с автоматической обработкой текста (например, информационный поиск, машинный перевод) и, на наш взгляд, является предтечей искусственного интеллекта.

Среди основных методов разрешения лексической многозначности выделяют: методы, использующие внешние источники информации и методы, базирующиеся на машинном обучении, работающие на размеченных корпусах текстов. Также применяются комбинации этих методов \cite{Lukash 2011} (с. 191--192). 

По другой классификации методы разрешения лексической многозначности
различают по типу используемых \textit{внешних источников информации}~\cite{Navigli 2009} (с. 10:6--10:8):
\begin{itemize}
\item структурированные источники данных (машиночитаемые словари, тезаурусы, онтологии). Тезаурусы содержат информацию об отношениях между словами, такими как: синонимия, антонимия и другие. Классическим примером тезауруса и машиночитаемого словаря для английского языка является WordNet, 
в котором слова организованы в виде \textit{синсетов} (от англ. \textit{\textbf{syn}onym \textbf{set}}, группа синонимов), отношения указаны между синсетами.
\item неструктурированные источники данных в виде корпусов текстов делятся на (а)~неразмеченные корпуса (raw corpora) и (б)~синтаксически и/или семантически размеченные корпуса.
\end{itemize}

На сегодняшний день на русском языке нет, по-видимому, достаточно объёмных и серьёзных обзоров по разрешению многозначности. Наиболее полное описание истории развития методов (20 страниц) есть в диссертации Д.~ Ю.~Турдакова~\cite{Trudakov 2010}. Такое положение дел послужило одной из причин написания этой статьи, которая будет заделом для полновесного обзора по данной теме.

Далее будут представлены примеры методов и алгоритмов разрешения лексической многозначности, разбитые на группы: 
\begin{itemize}
\item нейронные сети --- многообещающие методы с богатой историей;
\item бустинг как метод улучшения точности алгоритма обучения;
\item лексические цепочки --- построение последовательности семантически связанных слов;
\item метод ансамбля байесовских классификаторов и сочетаемостные ограничения на основе байесовских сетей;
\item контекстная кластеризация --- кластеризация контекстных векторов, где разные кластеры соответствуют разным значениям слова;
\item кластеризация слов --- это кластеризация семантически близких слов, при этом кластер соответствует некоторому значению.
\end{itemize}

Данная статья является <<введением>> в проблематику WSD, поскольку эта тема является чрезвычайно обширной и существуют сотни интересных работ по каждому из затронутых направлений.

\input{./chapter/Kirillov_seti}
\input{./chapter/chirkova_busting.tex}
\input{./chapter/Pilinovich_lexical_chains}

\bfullwidth
\begin{center}
\section{Байесовский классификатор и сочетаемостные ограничения}
\end{center}
\efullwidth

В первой части главы строится ансамбль наивных байесовских классификаторов. Наивный байесовский классификатор --- это простой вероятностный классификатор на основе применения теоремы Байеса. Для различения значений учитывается совместная встречаемость слов в окне заданного размера в текстах корпуса.

Во второй части главы для каждого глагола строится байесовская сеть. Байесовская модель обучается сочетаемостным ограничениям глаголов, то есть обучается тому --- с какими существительными глаголы могут употребляться. Сочетаемостные ограничения позволяют ограничить число значений целевого слова по данным контекста~\cite{Navigli 2009} (с. 10:32). Связи глагол-существительное извлекаются из корпуса текстов, а классы существительных задаются тезаурусом WordNet. Маловероятные значения слов при построении сочетаемостных ограничений отбрасываются (стратегия “explaining away”).

%\columnbreak
\input{./chapter/Chuharev_bayes}
\input{./chapter/Sikhonina_bayes_seti}

\pagebreak
\bfullwidth
\begin{center}
\section{Контекстная кластеризация}
\end{center}
\efullwidth
Каждому вхождению анализируемого слова в корпус соответствует контекстный вектор. Выполняется кластеризация векторов, где разные кластеры соответствуют разным значениям слова~\cite{Navigli 2009} (с. 10:26--10:28). Алгоритмы кластеризации полагаются на дистрибутивную гипотезу (Distributional Hypothesis)~\cite{Harris 1985}, в~соответствии с которой слова, употребляемые в схожих контекстах, считаются близкими по смыслу. 

В первой части выполняется разрешение лексической многозначности и поиск новых значений 
на основе контекстных векторов, построенных по биомедицинским текстам. 

Во второй части представлена задача \textit{различения значений слов}. Эта задача отличается от задачи разрешения лексической многозначности тем, что при различении значений слов нет никаких предопределенных значений слова, присоединенных к кластерам; здесь слова, употребляющиеся в схожих контекстах, группируются в кластеры (значения).

\input{./chapter/Yaryshkina_clustering_medtekst.tex}
\columnbreak
\input{./chapter/Spirkova_vektor_specific.tex}

\bfullwidth
\begin{center}
\section{Кластеризация слов}
\end{center}
\efullwidth
Кластеризация слов --- это кластеризация семантически близких слов, при этом кластер соответствует одному из значений исследуемого слова~\cite{Navigli 2009} (с. 10:28--10:29).

В первой части описан метод построения пары взаимных ближайших соседей 
и автоматического создания тезауруса.
Для этого из текста извлекаются тройки зависимостей (слово 1, слово 2, отношение), 
затем эти тройки используются для вычисления близости значений слов.

Алгоритм кластеризации посредством комитетов, представленный во второй части раздела,
также можно отнести к задаче \textit{различения значения слов}. 
В алгоритме последовательно вычисляется сходство между словами,  строится набор компактных кластеров (комитетов), все слова распределяются по этим кластерам

\input{./chapter/Shorets_clustering.tex}
\columnbreak
\input{./chapter/Yankevich_komitetj.tex}

\newpage
\bfullwidth
\begin{center}
\section{Эксперименты}
\end{center}
\efullwidth
\input{./chapter/Korzhitsky_compare.tex}

\section{Заключение}

Разрешение лексической многозначности - это задача выбора между разными значениями слов и словосочетаний в словаре в зависимости от контекста. Задача разрешения лексической многозначности является открытой проблемой, то есть крайне интересной и привлекательной с научной точки зрения.

В статье представлен краткий обзор методов и алгоритмов, применяемых для разрешения лексической многозначности. Эти методы используют различный математический и алгоритмический аппарат для решения WSD-задачи: нейронные сети, адаптивный алгоритм улучшения точности обучения AdaBoost, построение лексических цепочек, методы на основе применения теоремы Байеса и методы кластеризации контекстных векторов и семантически близких слов. Работу завершает исследование, в котором сравниваются время обучения, время работы и результаты работы разных алгоритмов решения WSD-задачи.

Работа Старковой В.Г. поддержана грантом РГНФ (проект № 15-04-12029), работа Кириллова А.Н. и Чирковой Ю.В. поддержана грантом РГНФ (проект № 15-04-12006). Работа Крижановского А. А. выполнена при частичной финансовой поддержке Программы фундаментальных исследований Секции литературы и языка ОИФН РАН «Язык  и информационные технологии» 2015-2017 (проект «Корпус вепсского языка: разработка и формирование морфологической базы электронного ресурса»).
 
\begin{thebibliography}{9}

\bibitem{Averin 2006}
\textit{Аверин А. Н.} Разработка сервиса поиска биграмм // Труды международной конференции «Корпусная лингвистика–2006. СПб., С.Петерб. ун-та., 2006. С. 5~ - 15.

\bibitem{epr:website}
\textit{Епрев А. С.} Применение контекстных векторов в классификации текстовых документов // 
“Журнал радиоэлектроники”.   2010. N 10. URL: http://jre.cplire.ru/iso/oct10/1/text.html (дата обращения: ).

\bibitem{Kim 1989}
\textit{Ким Дж. О., Мьюллер Ч. У., Клекка У. Р.} Факторный, дискриминантный и кластерный анализ / <<Финансы и статистика>>, Москва, Россия. 1989. Стр.172.

\bibitem{Lukash 2011}
\textit{Лукашевич Н. В.} Тезаурусы в задачах информационного поиска / Издательство МГУ, 2011. 495 с.

\bibitem{Marmanis}
\textit{Марманис~Х., Бабенко Д.} Алгоритмы интеллектуального Интернета. Передовые методики сбора, анализа и обработки данных. – Пер. с англ. – СПб.: Символ-Плюс, 2011. 480 с.

\bibitem{Paclin}
\textit{Паклин~Н.~Б., Орешков~В.~И.}Бизнес-аналитика: от данных к знаниям: Учебное пособие. 2-е изд., испр. --- СПб.: Питер, 2013. --- 704~с.

\bibitem{Trudakov 2010}
\textit{Турдаков Д. Ю.} Методы и программные средства разрешения лексической многозначности терминов на основе сетей документов: дис. … канд. физико-математических наук:  Москва, 2010.  138 c.

\bibitem{Abney 1999}
\textit{Abney S. and Light M.} Hiding a semantic hierarchy in a markov model. In Proceedings of the Workshop on Unsupervised Learning in Natural Language Processing, ACL. 1999.

\bibitem{Azzini}
\textit{Azzini A., da Costa Pereira C., Dragoni M. and Tettamanzi A. G. B.} Evolving Neural Networks for Word Sense Disambiguation // 8-th International conference on hybrid intelligent systems. Spain. Barcelona, 2008. P. 332–337. doi: 10.1109/HIS.2008.88

\bibitem{Barzilay Elhadad 1997}
\textit{Barzilay R. and  Elhadad M. }Using lexical chains for text summarization // In Proceedings of the ACL Workshop on Intelligent Scalable Text Summarization (Madrid, Spain). 1997. P. 10–17.

\bibitem{Berry 1993}
\textit{Berry M.,  Do T.,  O’Brien G.,  Krishna V. and Varadhan S. }SVDPACK (version 1.0) user’s guide. Technical Report CS-93-194, University of Tennessee at Knoxville, Computer Science Department, April 1993.

\bibitem{Breiman}
\textit{L.~Breiman.} Arcing classifiers. The Annals of Statistics. Vol 26 (3), 1998, pp. 801–849.

\bibitem{Bruce 1994}
\textit{Bruce R. and  Wiebe J. }Word-sense disambiguation using decomposable models // In Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics, 1994. P. 139–146. doi: 10.3115/981732.981752

\bibitem{Wu}
\textit{Carpuat M. and Wu D.} Evaluating the word sense disambiguation performance of statistical machine translation. In Proceedings of the second international joint conference on natural language processing (IJCNLP), 2005, pp. 122–127. URL: http://www.aclweb.org/anthology/I05-2021

\bibitem{Ciaramita 2000}
\textit{Ciaramita M. and  Johnson M.} Explaining away ambiguity: Learning verb selectional preference with Bayesian networks. In Proceedings of the 18th conference on Computational linguistics, vol. 1, 2000, pp. 187–193.

\bibitem{COTTRELL 1983}
\textit{Cottrell G. W. and  Small S. L. }A connectionist  scheme for modelling word  sense  disambiguation // Cognition and brain theory. 1983. № 6. P. 89–120. 

\bibitem{COTTRELL 1989}
\textit{Cottrell G. W. }A connectionist approach to word sense disambiguation / Pitman, London, 1989.

\bibitem{Do Thuy Duong 2011}
\textit{Duong D. T. }Automated text summarization. Graduation Thesis. Hanoi University. 2011. 

\bibitem{Donald 1990}
\textit{Hindle D. }Noun classification from predicate-argument structures // In Proceedings of ACL-90, Pittsburg, Pennsylvania, June, 1990. P. 268-275.

%\bibitem{Charles 1993}
%\textit{Ling Charles X.,  Marinov M. }Answering the connectionist challenge: A symbolic model of learning the past tenses of English verbs,  %Cognition, Elsevier, 1993.

%\bibitem{Dekang 1998}
%\textit{Lin D. }Automatic Retrieval and Clustering of Similar Words.Proceedings of the 17th international conference on Computational %linguistics-Volume 2. – Association for Computational Linguistics, Department of Computer Science University of Manitoba Winnipeg, Manitoba, %Canada, 1998, pp. 768-774. DOI: 10.3115/980432.980696

%\bibitem{Dekang 1993}
%\textit{Lin D. }Principle-based parsing without overgeneration. In Proceedings of ACL-93, Columbus, Ohio, 1993, pp. 112-120. DOI: %10.3115/981574.981590

%\bibitem{Dekang 1997}
%\textit{Lin D. }Using syntactic dependency as local context to resolve word sense ambiguity. In Proceedings of ACL/EACL-97, Madrid, Spain, %July, 1997, pp. 64-71. DOI: 10.3115/979617.979626

%\bibitem{Donald 1990}
%\textit{Hindle D. }Noun classification from predicate-argument structures. In Proceedings of ACL-90, Pittsburg, Pennsylvania, June, 1990, pp. %268-275.

%\bibitem{Do Thuy Duong 2011}
%\textit{Duong D. T. }Automated text summarization. Graduation Thesis. Hanoi University. 2011. 

\bibitem{esc1}
\textit{Escudero G., M\`{a}rquez L. and Rigau G.} Using LazyBoosting for word sense disambiguation. 
In Proceedings of the Second International Workshop on evaluating Word Sense Disambiguation Systems. Toulouse, France, 2001, pp. 71–74.

\bibitem{esc2}
\textit{Escudero G., M\`{a}rquez L. and Rigau G.} Boosting Applied to Word Sense Disambiguation. In Proceedings of the 12th 
European Conference on Machine Learning, ECML. Barcelona, Catalonia. 2000. 

\bibitem{Freund 1999}
\textit{Freund Y., Schapire R. E. }A Short Introduction to Boosting // AT\&T Labs Research, Shannon Laboratory.  1999.

\bibitem{Freund 1996}
\textit{Freund Y.,  Schapire R. E. }Game theory, on-line prediction and boosting // In Proceedings of the Ninth Annual Conference on Computational Learning Theory,  1996. P. 325-332.

\bibitem{Freund 1997}
\textit{Freund Y.,  Schapire R. E. }A decision-theoretic generalization of on-line learning and an application to boosting // Journal of Computer and System Sciences. 1997. P. 119–139. doi: 10.1006/jcss.1997.1504

\bibitem{Halliday Hasan 1976}
\textit{Halliday M. and  Hasan R. }Cohesion in English / London: Longman. 1976. 

\bibitem{Harris 1985}
\textit{Harris Z. }Distributional structure / In: Katz, J. J. (ed.) The Philosophy of Linguistics. New York: Oxford University Press. 1985. P. 26–47

\bibitem{Hearst 1994}
\textit{Hearst M. }Multi-paragraph segmentation of expository text // In Proceedings of the 32th Annual Meeting of the Association for Computational Linguistics, 9–16. Las Cruces, New Mexico: Association for Computational Linguistics. 1994. doi: 10.3115/981732.981734

\bibitem{Hinton 1986}
\textit{Hinton G. E.,  McClelland J. L.,  Rumelhart D. E.} Distributed representations // In Parallel Processing: explorations in the microstructure of cognition. MIT Press, Cambridge, MA, 1986. P. 5–44.

\bibitem{Hirst St-Onge 1998}
\textit{Hirst G. and  St-Onge D. }Lexical chains as representations of context for the detection and correction of malapropisms. WordNet: An electronic lexical database, 1998. P. 305-332.

\bibitem{Hoey 1991}
\textit{Hoey M. }Patterns of Lexis in Text / Oxford: Oxford University Press. 1991. 

\bibitem{Jain 1988}
\textit{Jain A. and  Dubes R. }Algorithms for Clustering Data / Prentice-Hall, Inc., Upper Saddle River, NJ, 1988.

\bibitem{Jain 1999}
\textit{Jain A.,  Murthy M. and  Flynn P. }Data clustering: a review // ACM Computing Surveys, 31(3):264-323, September 1999. doi: 10.1145/331499.331504

\bibitem{Leacock 1993}
\textit{Leacock C.,  Towell G. and  VoorheesE. }Corpus-based statistical sense resolution // In Proceedings of the ARPA Workshop on Human Language Technology, March. 1993, P. 260–265.  

\bibitem{LESK 1986}
\textit{Lesk M. }Automatic sense disambiguation using machine readable dictionaries: How to tell a pine cone from an ice cream cone //  Proceedings  of  the 5th SIGDOC. New York. 1986. P. 24–26. doi: 10.1145/318723.318728

\bibitem{Dekang 1998}
\textit{Lin D. }Automatic Retrieval and Clustering of Similar Words // Proceedings of the 17th international conference on Computational linguistics-Vol. 2. –  Department of Computer Science University of Manitoba Winnipeg, Manitoba, Canada, 1998, P. 768-774. doi: 10.3115/980432.980696

\bibitem{Dekang 1993}
\textit{Lin D. }Principle-based parsing without overgeneration // In Proceedings of ACL-93, Columbus, Ohio, 1993, P. 112-120. doi: 10.3115/981574.981590

\bibitem{Dekang 1997}
\textit{Lin D. }Using syntactic dependency as local context to resolve word sense ambiguity // In Proceedings of ACL/EACL-97, Madrid, Spain, July, 1997, P. 64-71. doi: 10.3115/979617.979626


\bibitem{Lin 2001}
\textit{Lin D. and Pantel P. }Induction of semantic classes from natural language text // In Proceedings of SIGKDD-01. San Francisco, CA. 2001. P. 317–322. doi: 10.1145/502512.502558  

\bibitem{Charles 1993}
\textit{Ling Charles X.,  Marinov M. }Answering the connectionist challenge: A symbolic model of learning the past tenses of English verbs /  Cognition, Elsevier, 1993.


\bibitem{Manning 1999}
\textit{Manning C. D. and  Sch\"utze H. }Foundations of Statistical Natural Language Processing / MIT Press. 1999.

\bibitem{Merz 1998}
\textit{Merz C. J. and  Murphy P. M. }UCI repository of machine learning databases, 1998. URL: www.ics.uci.edu/ mlearn/MLRepository.html (дата обращения: 24.04.2015).

\bibitem{Miller 1990}
\textit{Miller G. }Wordnet: An on-line lexical database // International Journal of Lexicography, 3(4). 1990.

\bibitem{Mooney 1996}
\textit{Mooney R. J. }Comparative Experiments on Disambiguating Word Senses:
An Illustration of the Role of Bias in Machine Learning / Department of Computer Sceinces, University of Texas, Austin, TX 78712-1188, 1996.

\bibitem{Mooney 1995}
\textit{Mooney R. J., Califf M. E. }Induction of First-Order Decision Lists: Results on Learning the Past Tense of English Verbs / Department of Computer Sceinces, University of Texas, Austin, TX 78712-1188, 1995.

\bibitem{Morris Hirst 1991}
\textit{Morris J. and  Hirst G. }Lexical cohesion computed by thesaural relations as an indicator of the structure of text // Computational Linguistics 17(1):21–43. 1991. 

\bibitem{Navigli 2009}
\textit{Navigli R. }Word sense disambiguation: A survey. ACM Computing Surveys (CSUR) 41, no. 2 (2009): 10. doi: 10.1145/1459352.1459355

\bibitem{Eugene 1975}
\textit{Nida Eugene A. }Componential Analysis of Meaning / The Hague, Mouton. 1975.


\bibitem{Pantel 2002}
\textit{Pantel P.,  Lin D. }Discovering Word Senses from Text / University of Alberta. Department of Computing Science Edmonton, Alberta T6H 2E1 Canada, 2002. doi: 10.1145/775047.775138

\bibitem{Pedersen 2000}
\textit{Pedersen T. }A Simple Approach to Building Ensembles of Naive Bayesian Classifers for Word Sense Disambiguation / Department of Computer Science, University of Minnesota Duluth. 2000.

\bibitem{Pedersen 1997}
\textit{Pedersen T. and  Bruce R. }Distinguishing word senses in untagged text / Proc.EMNLP.Providence, RI, 1997.

\bibitem{Purandare 2004}
\textit{ Purandare A. and  Pedersen T. }Improving word sense discrimination with gloss augmented feature vectors // Workshop on Lexical Resources for the Web and Word Sense Disambiguation.  2004.  P. 123-130. 

\bibitem{Quinlan 1993}
\textit{Quinlan J. R. }C4.5: Programs for Machine Learning / Morgan Kaufmann, 1993. 

\bibitem{Resnik 1997}
\textit{Resnik P. }Selectional preference and sense disambiguation / In Proceedings of the ANLP-97 Workshop: Tagging Text with Lexical Semantics: Why, What, and How? 1997.

\bibitem{Savova 2005}
\textit{Savova G., Pedersen T., Purandare A., Kulkarni A. }Resolving ambiguities in biomedical text with unsupervised clustering approaches / University of Minnesota Supercomputing Institute Research Report, 2005.

\bibitem{schapire99}
\textit{Schapire R. E. and Singer Y.} Improved Boosting Algorithms Using Confidence-rated Predictions. 
Machine Learning, vol. 37(3), 1999, pp. 297–336.

\bibitem{Schapire 1998}
\textit{Schapire R. E. and Singer Y. }Improved boosting a predictions // In Proceedings of the Eleventh Annual Confere Theory, 1998. P. 80–91. 

\bibitem{Schapire 1997}
\textit{Schapire R. E. }Using output codes to boost multiclass learning problems. In Machine Learning // Proceedings of the Fourteenth International Conference, 1997. P. 313–321. 

\bibitem{Schutze 1998}
\textit{Sch$\ddot{u}$tze H. }Automatic Word Sense Discrimination // Computational Linguistics, vol. 24, number 1., 1998.

\bibitem{SC:website}
\textit{SenseClusters. }  \newline URL: http://senseclusters.sourceforge.net (дата обращения: 24.04.2015).

\bibitem{UMLS:website}
\textit{UMLS Terminology Services (UTS).} URL: http://umlsks.nlm.nih.gov/kss/servlet/Turbine/\newline template (дата обращения: 22.04.2015)

\bibitem{VERONIS 1990}
\textit{Veronis J. and Ide N. }Word  sense  disambiguation  with  very  large neural  networks  extracted  from machine readable dictionaries // Proceedings of the 13th International Conference on Computational Linguistics. Helsinki. 1990. P. 389–394. doi: 10.3115/997939.998006

\bibitem{WALTZ 1985}
\textit{Waltz D. L. and  Pollack J. B. }Massively parallel parsing: a strongly interactive  model  of  natural  language interpretation // Cognitive science. 1985. № 9. P. 51–74. doi: 10.1207/s15516709cog0901\_4
                     
\bibitem{Weeber 2001}
\textit{Weeber M.,  Mork J.,  Aronson A. }Developing a test collection for biomedical word sense disambiguation / Proc. AMIA., 2001.

\bibitem{Zhao 2002}
\textit{Zhao Y. and  Karypis G. }Evaluation of hierarchical clustering algorithms for document datasets // In Proceedings of the 11th International Conference on Information and Knowledge Management, McLean, VA, 2002. P. 515-524. doi: 10.1145/584792.584877

\end{thebibliography}
\end{articletext}


\section{СВЕДЕНИЯ ОБ АВТОРE:}

\begin{aboutauthors}
\authorsname{Каушинис Татьяна Викторовна}
Студентка\\
Математический факультет\\ 
Петрозаводский государственный университет\\
пр-кт Ленина, 33, Петрозаводск, Республика Карелия\\
тел.: (8142) 711078\\
эл. почта: merilstreet@mail.ru

\columnbreak

\authorsname{Kaushinis, Tatiana}
Petrozavodsk State University\\
33, Lenin Str., 185910, Petrozavodsk, Republic of Karelia, Russia\\
tel.: (8142) 711078\\
e-mail: merilstreet@mail.ru
\end{aboutauthors}

\begin{aboutauthors}
\authorsname{Кириллов Александр Николаевич}
Доктор физико-математических наук\\ 
доцент\\
Институт прикладных математических исследований Карельского научного центра РАН\\ 
ул. Пушкинская, 11, Петрозаводск, Республика Карелия, Россия, 185910\\
эл. почта: kirillov@krc.karelia.ru\\
тел.: (8142) 766312

\columnbreak

\authorsname{Kirillov, Alexander}
Institute of Applied Mathematical Research, Karelian Research Centre, Russian Academy of Sciences\\
11, Pushkinskaya St., 185910 Petrozavodsk, Karelia, Russia\\
e-mail: kirillov@krc.karelia.ru\\
tel.: (8142) 766312
\end{aboutauthors}

\begin{aboutauthors}
\authorsname{Коржицкий Никита Иванович}
Студент\\
Математический факультет\\ 
Петрозаводский государственный университет\\
пр-кт Ленина, 33, Петрозаводск, Республика Карелия\\
тел.: (8142) 711078\\
эл. почта: nikita@nikita.tv

\columnbreak

\authorsname{Korzhitsky, Nikita}
Petrozavodsk State University\\
33, Lenin Str., 185910, Petrozavodsk, Republic of Karelia, Russia\\
tel.: (8142) 711078\\
e-mail: nikita@nikita.tv 
\end{aboutauthors}

\begin{aboutauthors}
\authorsname{Крижановский Андрей Анатольевич}
Кандитат технических наук\\ 
Институт прикладных математических исследований Карельского научного центра РАН\\ 
ул. Пушкинская, 11, Петрозаводск, Республика Карелия, Россия, 185910\\
эл. почта: andew.krizhanovsky@gmail.com\\
тел.: (8142) 766312

\columnbreak

\authorsname{Krizhanovsky, Andrew}
Institute of Applied Mathematical Research, Karelian Research Centre, Russian Academy of Sciences\\
11, Pushkinskaya St., 185910 Petrozavodsk, Karelia, Russia\\
e-mail: andew.krizhanovsky@gmail.com\\
tel.: (8142) 766312
\end{aboutauthors}

\begin{aboutauthors}
\authorsname{Пилинович Александр Владимирович}
Студент\\
Математический факультет\\ 
Петрозаводский государственный университет\\
пр-кт Ленина, 33, Петрозаводск, Республика Карелия\\
тел.: (8142) 711078\\
эл. почта: alexander.pilinovich@yandex.ru

\columnbreak

\authorsname{Pilinovich, Aleksander}
Petrozavodsk State University\\
33, Lenin Str., 185910, Petrozavodsk, Republic of Karelia, Russia\\
tel.: (8142) 711078\\
e-mail: alexander.pilinovich@yandex.ru 
\end{aboutauthors}

\begin{aboutauthors}
\authorsname{Сихонина Ирина Александровна}
Студентка\\
Математический факультет\\ 
Петрозаводский государственный университет\\
пр-кт Ленина, 33, Петрозаводск, Республика Карелия\\
тел.: (8142) 711078\\
эл. почта: syawenka@mail.ru

\columnbreak

\authorsname{Sikhonina, Irina}
Petrozavodsk State University\\
33, Lenin Str., 185910, Petrozavodsk, Republic of Karelia, Russia\\
tel.: (8142) 711078\\
e-mail: syawenka@mail.ru 
\end{aboutauthors}

\begin{aboutauthors}
\authorsname{Спиркова Анна Михайловна}
Студентка\\
Математический факультет\\ 
Петрозаводский государственный университет\\
пр-кт Ленина, 33, Петрозаводск, Республика Карелия\\
тел.: (8142) 711078\\
эл. почта: annspirkova@gmail.com

\columnbreak

\authorsname{Spirkova, Anna}
Petrozavodsk State University\\
33, Lenin Str., 185910, Petrozavodsk, Republic of Karelia, Russia\\
tel.: (8142) 711078\\
e-mail: annspirkova@gmail.com
\end{aboutauthors}

\begin{aboutauthors}
\authorsname{Старкова Валентина Геннадьевна}
Старший инженер-программист\\ 
Институт прикладных математических исследований КарНЦ РАН\\ 
ул. Пушкинская, 11, Петрозаводск, Республика Карелия, Россия, 185910\\
тел.: (8142) 766312\\
эл. почта: stark\_val@mail.ru

\columnbreak

\authorsname{Starkova, Valentina}
Institute of Applied Mathematical Research, Karelian Research Centre, Russian Academy of Sciences\\
11, Pushkinskaya St., 185910 Petrozavodsk, Karelia, Russia\\
tel.: (8142) 766312\\
e-mail: stark\_val@mail.ru 
\end{aboutauthors}

\begin{aboutauthors}
\authorsname{Степкина Татьяна Владимировна}
Студентка\\
Математический факультет\\ 
Петрозаводский государственный университет\\
пр-кт Ленина, 33, Петрозаводск, Республика Карелия\\
тел.: (8142) 711078\\
эл. почта: hogdp@mail.ru

\columnbreak

\authorsname{Stepkina, Tatiana}
Petrozavodsk State University\\
33, Lenin Str., 185910, Petrozavodsk, Republic of Karelia, Russia\\
tel.: (8142) 711078\\
e-mail: hogdp@mail.ru
\end{aboutauthors}

\begin{aboutauthors}
\authorsname{Ткач Станислав Сергеевич}
Студент\\
Математический факультет\\ 
Петрозаводский государственный университет\\
пр-кт Ленина, 33, Петрозаводск, Республика Карелия\\
тел.: (8142) 711078\\
эл. почта: tkachkras@gmail.com

\columnbreak

\authorsname{Tkach, Stanislav}
Petrozavodsk State University\\
33, Lenin Str., 185910, Petrozavodsk, Republic of Karelia, Russia\\
tel.: (8142) 711078\\
e-mail: tkachkras@gmail.com 
\end{aboutauthors}

\begin{aboutauthors}
\authorsname{Чиркова Юлия Васильевна}
Кандидат физико-математических наук\\ 
Институт прикладных математических исследований КарНЦ РАН\\ 
ул. Пушкинская, 11, Петрозаводск, Республика Карелия, Россия, 185910\\
тел.: (8142) 766312
эл. почта: julia@krc.karelia.ru

\columnbreak

\authorsname{Chirkova, Julia}
Institute of Applied Mathematical Research, Karelian Research Centre, Russian Academy of Sciences\\
11 Pushkinskaya St., 185910 Petrozavodsk, Karelia, Russia\\
tel.: (8142) 766312
e-mail: julia@krc.karelia.ru
\end{aboutauthors}

\begin{aboutauthors}
\authorsname{Чухарев Алексей Леонидович}
Старший инженер-программист\\ 
Институт прикладных математических исследований КарНЦ РАН\\ 
ул. Пушкинская, 11, Петрозаводск, Республика Карелия, Россия, 185910\\
тел.: (8142) 766312
эл. почта: chuharev@krc.karelia.ru

\columnbreak

\authorsname{Chuharev, Alexey}
Institute of Applied Mathematical Research, Karelian Research Centre, Russian Academy of Sciences\\
11, Pushkinskaya St., 185910 Petrozavodsk, Karelia, Russia\\
tel.: (8142) 766312
e-mail: chuharev@krc.karelia.ru
\end{aboutauthors}

\begin{aboutauthors}
\authorsname{Шорец Дарья Сергеевна}
Студентка\\ 
Математический факультет\\ 
Петрозаводский государственный университет\\
пр-кт Ленина, 33, Петрозаводск, Республика Карелия\\
тел: (8142) 711078\\
эл. почта: da\_sha1078@mail.ru

\columnbreak

\authorsname{Shorets, Daria}
Petrozavodsk State University\\
33, Lenin Str., 185910, Petrozavodsk, Republic of Karelia, Russia\\
tel.: (8142) 711078\\
e-mail: da\_sha1078@mail.ru
\end{aboutauthors}

\begin{aboutauthors_without_page_numbering}
\authorsname{Ярышкина Екатерина Александровна}
Студентка\\ 
Математический факультет\\ 
Петрозаводский государственный университет\\
пр-кт Ленина, 33, Петрозаводск, Республика Карелия\\
тел:(8142) 711078\\
эл. почта: kate.rysh@gmail.com

\columnbreak

\authorsname{Yaryshkina, Ekaterina}
Petrozavodsk State University\\
33, Lenin Str., 185910, Petrozavodsk, Republic of Karelia, Russia\\
tel.: (8142) 711078\\
e-mail: kate.rysh@gmail.com 
\end{aboutauthors_without_page_numbering}

\begin{aboutauthors_without_page_numbering}
\authorsname{Янкевич Дарья Юрьевна}
Студентка\\ 
Математический факультет\\ 
Петрозаводский государственный университет\\
пр-кт Ленина, 33, Петрозаводск, Республика Карелия\\
тел: (8142) 711078\\
эл. почта: dyankevic@gmail.com

\columnbreak

\authorsname{Yankevich, Daria}
Petrozavodsk State University\\
33, Lenin Str., 185910, Petrozavodsk, Republic of Karelia, Russia\\
tel.: (8142) 711078\\
e-mail: dyankevic@gmail.com
\end{aboutauthors_without_page_numbering}


\end{document}
