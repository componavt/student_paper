\section{Выявление значений слов из текста~--- кластеризация посредством комитетов}
\begin{flushright}
\textit{Д. Ю. Янкевич} 
\end{flushright}

В статье \cite{Pantel 2002} представлен алгоритм автоматического обнаружения значений слов в тексте, названный \textit{кластеризация посредством комитетов} (Clustering By Committee, далее CBC). Также авторы предлагают методологию оценки для автоматического измерения точности и полноты найденных значений.

\textbf{Алгоритм} первоначально находит множество компактных кластеров, называемых комитетами, каждый из которых представляет собой одно из значений определяемого слова. Центр тяжести  членов комитета (мера связности с определяемым словом) используется в качестве вектора признаков кластера.

Алгоритм CBC включает три этапа.

\textit{На этапе I для каждого элемента (слова) вычисляется $k$ наиболее похожих слов, строится база данных сходства $S$}. Сначала весь список относящихся к слову значений сортируется по убыванию значений связи согласно значению PMI (точечная взаимная информация, pointwise mutual information~\cite{Manning 1999}, с.~66--68), а затем, с помощью иерархического кластерного анализа по \textit{методу средней связи} \cite{Kim 1989}, вычисляется сходство между всеми элементами кластера попарно. Значение функции PMI между предполагаемым значением слова (контекстом) и элементом (словом) вычисляется следующим образом: пусть $x$ --- это рассматриваемый элемент, а $y$ --- контекст. \textit{Точечная взаимная информация} между $x$ и $y$ определена как:

$$
pmi(x;y)\equiv log \frac{\displaystyle p(x,y)}{\displaystyle p(x)p(y)}=
$$
$$
=log\frac{\displaystyle p(x|y)}{\displaystyle p(x)}=log\frac{\displaystyle p(y|x)}{\displaystyle p(y)}.
$$

\begin{algorithm*}
\SetAlgoLined
\KwData{$(E, S, \theta_1, \theta_2)$, где  $E$ --- это список элементов, которые будут сгруппированы, база данных сходства $S$ (построена в ходе этапа I), пороги $\theta_1$ и $\theta_2$ (с помощью порога $\theta_1$ сохраняются только те кластеры, которые имеют значения, отличные от ранее обнаруженных, порог $\theta_2$ позволяет обнаружить элементы, не принадлежащие ни одному из кластеров)}
\KwResult{$C$ --- список комитетов}
\textbf{Step 1:}\\
\ForEach{$e \in E$}{\begin{enumerate}
\item Кластер $k$ наиболее <<близких>> (похожих) элементов $e$ из $S$ с помощью метода  \newline средней связи.
\item Для каждого обнаруженного кластера $c$ вычислить следующую оценку:
$val = | C | \times avgsim(c)$, где $| C |$ --- количество элементов $c$ и $avgsim(c)$ --- усредненное сходство между всеми парами элементов кластера $c$.
\item Записать кластер с наивысшей оценкой в список $L$.\end{enumerate}}
\textbf{Step 2:}\\
SortByDecreasingOrder$(c(val) \in L)$ // Сортировка кластеров в списке $L$ в порядке убывания их оценок $val$.\\
\textbf{Step 3:}\\
$C = \emptyset$ // Пусть  перечень комитетов $C$ будет изначально пустым.\\
\ForEach{$c \in L$}{// в отсортированном по убыванию порядке:
\begin{enumerate}
\item Вычислить центр тяжести, усредняя поэлементно значение векторов, и вычислить 
\newline вектор  PMI центроида (так же, как и для отдельных элементов на шаге 1).
\item Если схожесть $c$ и центроида каждого комитета, ранее добавленного к $C$, ниже порогового $\theta_1$, то следует добавить $c$ в $C$.
\end{enumerate}}
\textbf{Step 4:}\\
\If{$C=\emptyset$}{\Return $C$}
\textbf{Step 5:}\\
$R = \emptyset$ // $R$ --- это множество остатков, т. е. элементов, не охваченных ни одним из кластеров\\
\ForEach
{$e \in E$}
%{\ForEach
%{$c \in C$}
{\If{$sim(e,$ foreach  $c \in C) < \theta_2$ //  сходство по всем комитетам из $C$ меньше $\theta_2$ // }
{$R += e$ // то следует добавить $e$ в список остатков $R$.}
%}
}
\textbf{Step 6:}\\
\If{$R=\emptyset$}{\Return $C$ \Else{\Return $C \cup Algorithm1(R, S, \theta_1, \theta_2)$}}
\caption{Этап II. Поиск комитетов}
\label{alg_phase2}
\end{algorithm*}

\begin{algorithm*}
\SetAlgoLined

\KwResult{Итоговые кластеры с максимальным значением связи $val$ между словами (см. вычисление $val$ на шаге 1 и 3 Алгоритма~\ref{alg_phase2})}
Пусть $C$ --- это список кластеров (изначально пустых).\\
Пусть $S$ --- это первые 200 кластеров, наиболее похожих на $e$ (база данных сходства $S$ построена в ходе этапа I).\\
\While{$S\neq\varnothing$}{пусть $c \in S$ наиболее близкий кластер к $e$\\
\If{сходство $(e, c) < \sigma$}{\textbf{конец цикла}}
\If{$c$ не схож ни с одним кластером в $C$}{присвоить $e$ к $c$;\\
удалить из $e$ его характеристики, которые перекрываются с характеристиками $c$;}
удалить $c$ из $S$
}
\caption{Этап III. Присвоение элементов кластерам: для каждого из элементов $e$ находится наиболее близкий кластер, в который  включается $e$}
\label{alg_phase3}
\end{algorithm*}

При кластеризации посредством метода средних связей \textit{(average-link clustering)} вычисляется среднее сходство между данным объектом и всеми объектами в кластере, а затем, если найденное \textit{среднее значение сходства} достигает или превосходит некоторый заданный пороговый уровень сходства, объект присоединяется к этому кластеру \cite{Kim 1989}. Сложность этого алгоритма $O(n^2 \times  log (n))$, 
где $n$~-- число кластеризуемых элементов \cite{Jain 1999}.

На II этапе Алгоритм~\ref{alg_phase2} рекурсивно строит набор компактных кластеров, удаленных друг от друга, где элементы каждого кластера образуют комитет. В ходе работы Алгоритма~\ref{alg_phase2} формируется как можно больше комитетов при условии, что каждый вновь созданный комитет не слишком похож на любой из уже существующих комитетов. Если условие нарушается, комитет просто отбрасывается.

На каждом рекурсивном уровне Алгоритм~\ref{alg_phase2} находит компактный набор кластеров (их и называем  комитетами) и определяет оставшиеся элементы, не вошедшие ни в один из комитетов. Будем говорить, что комитет <<покрывает>> элемент (или элемент <<входит>> в комитет), если значение сходства между элементом и центроидом комитета выше некоторой пороговой величины. При следующем рекурсивном вызове алгоритм снова ищет комитеты среди оставшихся элементов. На выходе Алгоритм~\ref{alg_phase2} дает список всех найденных комитетов.

На шаге 1 Алгоритма~\ref{alg_phase2} поиска комитетов предпочтение отдается большим и компактным кластерам.
На шаге 2 кластеры сортируются по значению сходства для последующего выбора лучшего кластера.
На шаге 3 кластер сохраняется только в том случае, если его сходство со всеми ранее полученными кластерами ниже установленного порогового значения (в экспериментах было получено значение $\theta_1=0,35$).
На шаге 4, если не было найдено комитетов на предыдущем шаге, рекурсия останавливается.
Оставшиеся и никуда не вошедшие элементы (остатки) определяются на шаге~5. Если таких остатков нет, то алгоритм завершается, иначе~-- алгоритм вызывается рекурсивно для остатков.

В результате второго этапа построения CBC строятся плотные компактные кластеры (имеющие б\'ольшее значение $val$, см. шаги 1 и 3 Алгоритма~\ref{alg_phase2}), хорошо отличающиеся друг от друга. На третьем этапе все элементы распределяются по этим кластерам, а именно: каждый элемент $e$ присваивается наиболее близкому кластеру, при этом центроид членов комитета используется в качестве вектора характеристик кластера (Алгоритм~\ref{alg_phase3}). Центроиды не изменяются, т. е. при добавлении элемента в кластер элемент не добавляется в комитет кластера.

Алгоритм CBC полагается на дистрибутивную гипотезу. 
Алгоритм CBC разрешает лексическую многозначность, группируя слова согласно сходству их контекстов. Каждому полученному кластеру соответствует одно из значений слова.

%В Табл.~\ref{yank} каждая запись показывает кластеры, которым принадлежит заглавное слово. Имена для кластеров Nq34, Nq137, $\ldots$ генерируются %автоматически. После каждого имени кластера находится число, обозначающее сходство между кластером и заглавным словом (т.е. рукав, сердце и одежда). %Далее перечисляются четыре слова, наиболее близкие центроиду кластера. Каждый кластер соответствует одному значению заглавного слова. Например, Nq34 %соответствует значению <<деталь одежды>>, а Nq137 соответствует значению <<ответвление русла реки>>.

%\begin{table}[H]
%\caption{Для построения кластеров использовались данные словарных статей Викисловаря: <<одежда>>,  <<рукав>> и  <<сердце>>}
%\begin{tabular}{|c|c|m{5cm}|}
%\hline
%\multicolumn{3}{|c|}{Рукав}\\
%\hline 
%Nq34 & 0.39 & деталь, манжета, полотно\\
%Nq137 & 0.20 & протока, русло, отмель, поток\\
%Nq217 & 0.18 & шланг, труба, огнетушитель\\
%\hline
%\multicolumn{3}{|c|}{Сердце}\\
%\hline
%Nq72 &  0.27 & орган, костный мозг, почка\\
%Nq866 & 0.17 & душа, рассудок, сознание\\
%\hline
%\multicolumn{3}{|c|}{Одежда}\\
%\hline
%Nq215 & 0.41 & мануфактура, юбка, брюки\\
%Nq235 & 0.20 & покрытие, оболочка, дорога\\
%\hline
%\end{tabular}
%\label{yank}
%\end{table}
%
%В табл.~\ref{yank} каждая запись показывает кластеры, которым принадлежит заглавное слово. Имена для кластеров Nq34, Nq137, $\ldots$ генерируются автоматически. После каждого имени кластера находится число, обозначающее сходство между кластером и заглавным словом (т.е.  {\it рукав}, {\it сердце} и {\it одежда}). Далее перечисляются четыре слова, наиболее близкие центроиду кластера. Каждый кластер соответствует одному значению заглавного слова. Например, Nq34 соответствует значению <<деталь одежды>>, а Nq137 соответствует значению <<ответвление русла реки>>.

\textbf{Сравнение с алгоритмом UNICON.} CBC является разновидностью алгоритма UNICON \cite{Lin 2001}, который также строит центроид кластера, используя небольшой набор похожих элементов.

Одним из основных различий между UNICON и CBC является то, что UNICON гарантирует, что различные комитеты не имеют одинаковых элементов, тем не менее \mbox{центры} тяжести двух комитетов по-прежнему могут быть очень близкими (похожими). В~UNICON'е эта проблема решается объединением таких кластеров. В отличие от этого на II этапе CBC создаются только те \mbox{комитеты}, центры тяжести которых отличны от всех ранее созданных комитетов.

Есть разница и на III этапе CBC. Алгоритм UNICON плохо работает со словами, которые имеют несколько широко используемых (доминирующих) значений. 
%Например, пусть значение <<отмычка>> является более употребимым для слова <<ключ>>, чем значение <<водный источник>>. Приведем общий список слов-синонимов для разных значений слова <<ключ>>: пневмоключ, электроключ, родник, родничок, источник, криница, гидроключ, ключик, тангента, треншальтер, тумблер, знак, контролька, отпирка, виброплекс, шифр. В этом списке 10 значений относятся к значению <<отмычка()>>, 4 к <<водный источник()>> и 2 к значению <<знак()>>. По этому списку алгоритмом UNICON будут сгенерированы кластеры <<отмычка>>, <<шифрование>>, <<происхождение>>,<<криптография>>, <<кнопка>>, <<водный источник>>,<<переключатель>>, <<намек>>. Сходство между словом и полученными кластерами  является очень низким, к тому же есть кластеры, содержащие одинаковые слова. 
%С другой стороны, 
CBC удаляет <<пересекающиеся>> (общие для двух кластеров) характеристики (слова) после того, как присвоит значение кластеру.
%(например, характеристики, относящиеся к значению <<отмычка>> слова <<ключ>>, будут удалены из вектора характеристик <<водный источник>>). 
%В результате сходство между  кластером <<водный источник (родник, родничок, источник, криница)>> и пересмотренным вектором характеристик кластера <<водный источник>> становится намного выше. Что, в свою очередь, 
Это приводит к тому, что кластеры точнее соответствуют искомым значениям.