\section{Автоматический поиск и кластеризация похожих слов}

\begin{flushright}
\textit{Д. С. Шорец} 
\end{flushright}

В работе \cite{Dekang 1998} представлена методология автоматического создания тезауруса, основанная на анализе корпуса текста и вычислении сходства слов, близости их значений. Значение незнакомого слова часто можно определить по контексту \cite{Eugene 1975}.  Рассмотрим, например, следующий текст:
\begin{flushright}
(1)\textit{Бутылка Tezg\"uino стоит на столе. Всем нравится Tezg\"uino. Tezg\"uino может привести к опьянению. Мы делаем Tezg\"uino из зерна.} 
\end{flushright}

Из этого контекста можно предположить, что \textit{Tezg\"uino} --- это алкогольный напиток, приготовленный из зерна.

Задача поиска похожих слов \textit{(similar words)} является первым шагом в определении значения слова. Тогда при обработке корпуса, включающего предложение (1), результатом должно быть определение близости значения слова \textit{Tezg\"uino} к словам \textit{пиво, вино, водка.}

\textbf{Методология автоматического создания тезауруса.} Для вычисления сходства между словами в работе \cite{Dekang 1998} использован парсер \cite{Dekang 1993}, извлекающий тройки из текста. Тройки зависимостей (от англ. \textit{dependency triple}, далее просто \textit{тройки}) состоят из двух слов и грамматического отношения между ними. Символ $||w, r, w'||$ означает частоту в корпусе тройки $(w, r, w')$, где $w, w'$ --- это слова в нормальной форме, $r$ --- синтаксическое отношение. Произвольное слово или отношение обозначается символом-джокером «*». Например, ||\textit{cook, obj,} *|| означает число троек со словом \textit{cook} и отношением \textit{obj}. 

Например из предложения \textit{<<У меня есть коричневая собака>>} будут извлечены следующие тройки:

\begin{center}
||\textit{коричневый, прил\_сущ, собака}||\\
||\textit{есть, гл\_сущ, собака}|| 
\end{center}

Определим следующие моменты:
\begin{enumerate} 
\item \textit{Описание слова w} --- это частоты всех троек ($w$, *, *) в корпусе,  то есть всех троек, включающих $w$. Описание слова $w$ является вектором.
\item \textit{<<Пересечение>> двух слов} --- это тройки, представленные в описании обоих слов; это пересечение векторов.
\end{enumerate}

Сходство между двумя объектами вычисляется как количество информации в <<пересечении>> двух объектов (2), деленное на количество информации в описании двух объектов (1), далее обозначено как функция \textit{sim($w_1, w_2$)} \cite{Dekang 1997}.

Предположив, что частоты троек не зависят друг от друга, получаем, что информация, представленная в описание слова $w$, равна сумме информации по каждой из уникальных троек в описании слова $w$. 

Для измерения информации в утверждении ||\textit{w, r, w'}||\textit{=с} выполним следующее:

\begin{enumerate}
\item измерим количество информации в утверждении, что произвольная тройка, извлеченная из текста, будет наша тройка \textit{(w, r, w')} при условии, что значение ||\textit{w, r, w'}|| --- не известно;
\item измерим то же при условии, что значение ||\textit{w, r, w'}|| --- известно;
\item разница этих двух количеств является ответом.
\end{enumerate}

Вероятность встретить в тексте тройку \textit{(w, r, w')} можно рассматривать как одновременное возникновение трех событий:

\textbf{A:} случайно выбранное слово - это $w$;

\textbf{B:} случайно выбранное отношение- это $r$;

\textbf{C:} случайно выбранное слово - это $w'$;

\begin{enumerate}
\item Когда значение ||\textit{w, r, w'}|| неизвестно, то предполагаем, что \textbf{А} и \textbf{С} являются условно независимыми при наличии события \textbf{В}.  Вероятность наступления сразу трех этих событий составляет \textbf{$P_{MLE}(B) P_{MLE} (A|B) P_{MLE} (C|B)$}, где \textbf{$P_{MLE}$} --- это оценка максимального правдоподобия распределения вероятностей (\textit{maximum likelihood estimation})

$P_{MLE}(B)=\frac{\displaystyle ||*,r,*||}{\displaystyle ||*,*,*||}$\\
$P_{MLE}(A|B)=\frac{\displaystyle ||w,r,*||}{\displaystyle ||*,r,*||}$\\
$P_{MLE}(C|B)=\frac{\displaystyle ||*,r,w'||}{\displaystyle ||*,r,*||}$

\item Когда значение ||\textit{w, r, w’}|| известно, можно сразу получить $P_{MLE}(A,B,C)$:

$P_{MLE}(A,B,C)=\frac{\displaystyle ||w,r,w'||}{\displaystyle ||*,*,*||}$
\item Пусть \textit{\textbf{I(w,r, w’)}} обозначает количество информации, содержащейся 
в утверждении ||\textit{w, r, w'}||\textit{=с}. Можно вычислить это значение так:
%
\begin{multline*}
I(w,r,w’)= \\
=-log(P_{MLE}(B) P_{MLE} (A|B) P_{MLE} (C|B))- \\
-(-log(P_{MLE}(A,B,C))= \\
=log\frac{||w,r,w'||\times||*,r,*||}{||w,r,*||\times||*,r,w'||}.
\end{multline*}
\end{enumerate}

Отметим, что значение \textit{I(w,r,w’)} равно количеству взаимной информации (\textit{mutual information}) между $w$ и $w'$ \cite{Donald 1990}.

Пусть $T(w)$ --– это множество пар \textit{(r, w')}, при которых $log\frac{\displaystyle ||w,r,w'||\times||*,r,*||}{\displaystyle ||w,r,*||\times||*,r,w'||}$ имеет положительное значение. Определим значение сходства (похожести) двух слов \textit{w1} и \textit{w2} с помощью формулы:

\begin{multline*}
sim(w_1,w_2)= \\
\frac{\displaystyle \sum_{(r,w)\in T(w_1)\cap T(w_2)}(I(w_1,r,w)+I(w_2,r,w))}{\displaystyle \sum_{(r,w)\in T(w_1)}I(w_1,r,w)+\sum_{(r,w)\in T(w_2)}I(w_2,r,w)}.
\end{multline*}

\textbf{Практическая реализация метода.} Был обработан корпус, включающий 64 млн. слов. Из него было извлечено 56,6 миллионов троек, включающих 8,7 миллиона уникальных троек.

Сам корпус был разбит на классы по частям речи.  Исследовалось попарно сходство между всеми глаголами, всеми существительными, всеми прилагательными/наречиями по формуле $sim(w_1 , w_2)$. Для каждого слова был построен аналог словарной статьи в тезаурусе, включающий упорядоченный набор 200 наиболее похожих слов. Статья в тезаурусе для слова $w$ имела следующий формат:\\

$w(pos):w_1,s_1,w_2,s_2,\ldots,w_N,s_N$\\

где \textit{pos} --– это часть речи, $w_i$ ---  это похожее слово, $s_i$ --- это значение сходства между $w$ и $w_i$, слова упорядочены по убыванию значения сходства.

Два слова являются \textit{парой взаимных ближайших соседей (RNN от respective nearest neighbors)}, если они являются наиболее похожими словами друг для друга (первыми в списке из двухсот слов). С помощью программы удалось получить 543 пары RNN существительных, 212 пар RNN глаголов, 382 пары RNN прилагательных/наречий в созданном автоматически тезаурусе. В Табл.~\ref{tabshor} представлен список каждого 10-го RNN для глаголов.

\bfullwidth
\begin{table}[H]
\centering
\caption{Список пар взаимных ближайших соседей (RNN) глаголов}
\begin{tabular}{|c|c|c|}
\hline
\textbf{Ранг} & \textbf{RNN} & \textbf{Значение сходства}\\
\hline
1 & \textit{fall rise} & 0,67\\
\hline
11 & \textit{injure kill} & 0,38\\
\hline
21 & \textit{concern worry} & 0,34\\
\hline
31 & \textit{convict sentence} & 0,29\\
\hline
41 & \textit{limit restrict} & 0,27\\
\hline
51 & \textit{narrow widen} & 0,26\\
\hline
61 & \textit{attract draw} & 0,24\\
\hline
71 & \textit{discourage encourage} & 0,23\\
\hline
81 & \textit{hit strike} & 0,22\\
\hline
91 & \textit{distregard ignore} & 0,21\\
\hline
101 & \textit{overstate understate} & 0,20\\
\hline
111 & \textit{affirm reaffirm} & 0,18\\
\hline
121 & \textit{inform notify} & 0,17\\
\hline
131 & \textit{differ vary} & 0,16\\
\hline
141 & \textit{scream yell} & 0,15\\
\hline
151 & \textit{laugh smile} & 0,143\\
\hline
161 & \textit{compete cope} & 0,136\\
\hline
171 & \textit{add whisk} & 0,130\\
\hline
181 & \textit{blossom mature} & 0,12\\
\hline
191 & \textit{smell taste} & 0,11\\
\hline
201 & \textit{bark howl} & 0,10\\
\hline
211 & \textit{black white} & 0,07\\
\hline
\end{tabular}
\label{tabshor}
\end{table}
\efullwidth
