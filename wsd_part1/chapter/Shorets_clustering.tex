\section{Автоматический поиск и кластеризация похожих слов}

\begin{flushright}
\textit{Д. С. Шорец} 
\end{flushright}

В работе \cite{Dekang 1998} представлен метод автоматического создания тезауруса, основанный на анализе корпуса текста и вычислении сходства слов, близости их значений. Значение незнакомого слова часто можно определить по контексту \cite{Eugene 1975}.  Рассмотрим, например, следующий текст:
\begin{flushright}
(1)\textit{Бутылка Tezg\"uino стоит на столе. Всем нравится Tezg\"uino. Tezg\"uino может привести к опьянению. Мы делаем Tezg\"uino из зерна.} 
\end{flushright}

Из этого контекста можно предположить, что \textit{Tezg\"uino} --- это алкогольный напиток, приготовленный из зерна.

Задача поиска похожих слов \textit{(similar words)} является первым шагом в определении значения слова. Тогда при обработке корпуса, включающего предложение (1), результатом должно быть определение близости значения слова \textit{Tezg\"uino} к словам \textit{пиво, вино, водка.}

\textbf{Методология автоматического создания тезауруса.} Для вычисления сходства между словами в работе \cite{Dekang 1998} использован парсер \cite{Dekang 1993}, извлекающий тройки из текста. Тройки зависимостей (от англ. \textit{dependency triple}, далее просто \textit{тройки}) состоят из двух слов и грамматического отношения между ними. Символ $||w, r, w'||$ означает частоту в корпусе тройки $(w, r, w')$, где $w, w'$ --- это слова в нормальной форме, $r$ --- синтаксическое отношение. Произвольное слово или отношение обозначается символом-джокером «*». Например, ||\textit{cook, obj,} *|| означает число троек со словом \textit{cook} и отношением \textit{obj}. 

Например, из предложения \textit{<<У меня есть коричневая собака>>} будут извлечены следующие тройки:

\begin{center}
||\textit{коричневый, прил\_сущ, собака}||\\
||\textit{есть, гл\_сущ, собака}|| 
\end{center}

Определим следующие моменты:
\begin{enumerate} 
\item \textit{Описание слова w} --- это частоты всех троек ($w$, *, *) в корпусе, т. е. всех троек, включающих $w$. Описание слова $w$ является вектором.
\item \textit{<<Пересечение>> двух слов} --- это тройки, представленные в описании обоих слов; это пересечение векторов.
\end{enumerate}

Сходство между двумя объектами вычисляется как количество информации в <<пересечении>> двух объектов (2), деленное на количество информации в описании двух объектов (1), далее обозначено как функция \textit{sim($w_1, w_2$)}~\cite{Dekang 1997}.

Предположив, что частоты троек не зависят друг от друга, получаем, что информация, представленная в описании слова $w$, равна сумме информации по каждой из уникальных троек в описании слова $w$. 

Для измерения информации в утверждении ||\textit{w, r, w'}||\textit{\,=\,с} выполним следующее:

\begin{enumerate}
\item измерим количество информации в утверждении, что произвольная тройка, извлеченная из текста, будет наша тройка \textit{(w, r, w')} при условии, что значение ||\textit{w, r, w'}||~-- не известно;
\item измерим то же при условии, что значение ||\textit{w, r, w'}||~-- известно;
\item разница этих двух количеств является ответом.
\end{enumerate}

Вероятность встретить в тексте тройку \textit{(w, r, w')} можно рассматривать как одновременное возникновение трех событий:

\textbf{A:} случайно выбранное слово~-- это $w$;

\textbf{B:} случайно выбранное отношение~-- это $r$;

\textbf{C:} случайно выбранное слово~-- это $w'$.

\begin{enumerate}
\item Когда значение ||\textit{w, r, w'}|| неизвестно, то предполагаем, что \textbf{А} и \textbf{С} являются условно независимыми при наличии события \textbf{В}.  Вероятность наступления сразу трех этих событий составляет \textbf{$P_{MLE}(B) P_{MLE} (A|B) P_{MLE} (C|B)$}, где \textbf{$P_{MLE}$} --- это оценка максимального правдоподобия распределения вероятностей (\textit{maximum likelihood estimation})

$P_{MLE}(B)=\frac{\displaystyle ||*,r,*||}{\displaystyle ||*,*,*||}$

$P_{MLE}(A|B)=\frac{\displaystyle ||w,r,*||}{\displaystyle ||*,r,*||}$

$P_{MLE}(C|B)=\frac{\displaystyle ||*,r,w'||}{\displaystyle ||*,r,*||}$

\item Когда значение ||\textit{w, r, w’}|| известно, можно сразу получить $P_{MLE}(A,B,C)$:

$P_{MLE}(A,B,C)=\frac{\displaystyle ||w,r,w'||}{\displaystyle ||*,*,*||}$
\item Пусть \textit{\textbf{I(w,r, w’)}} обозначает количество информации, содержащейся 
в утверждении ||\textit{w, r, w'}||\textit{\,=\,с}. Можно вычислить это значение так:
%
\begin{multline*}
I(w,r,w’)= \\
-log(P_{MLE}(B) P_{MLE} (A|B) P_{MLE} (C|B))- \\
-(-log(P_{MLE}(A,B,C))= \\
=log\frac{||w,r,w'||\times||*,r,*||}{||w,r,*||\times||*,r,w'||}.
\end{multline*}
\end{enumerate}

Отметим, что значение \textit{I(w,r,w’)} равно количеству взаимной информации (\textit{mutual information}) между $w$ и $w'$ \cite{Donald 1990}.

Пусть $T(w)$~-- это множество пар \textit{(r, w')}, при которых $$log\frac{\displaystyle ||w,r,w'||\times||*,r,*||}{\displaystyle ||w,r,*||\times||*,r,w'||}$$ имеет положительное значение. Определим значение сходства (похожести) двух слов \(w_1\) и \(w_2\) с помощью формулы:

\begin{multline*}
sim(w_1,w_2)= \\
\frac{\displaystyle \sum_{(r,w)\in T(w_1)\cap T(w_2)}(I(w_1,r,w)+I(w_2,r,w))}{\displaystyle \sum_{(r,w)\in T(w_1)}I(w_1,r,w)+\sum_{(r,w)\in T(w_2)}I(w_2,r,w)}.
\end{multline*}

\textbf{Практическая реализация метода.} Был обработан корпус, включающий 64 млн слов. Из него было извлечено 56,6 млн троек, включающих 8,7 млн уникальных троек.

Сам корпус был разбит на классы по частям речи.  Исследовалось попарно сходство между всеми глаголами, всеми существительными, всеми прилагательными/наречиями по формуле $sim(w_1 , w_2)$. Для каждого слова был построен аналог словарной статьи в тезаурусе, включающий упорядоченный набор 200 наиболее похожих слов. Статья в тезаурусе для слова $w$ имела следующий формат:\\

$w(pos):w_1,s_1,w_2,s_2,\ldots,w_N,s_N$,\\

\noindentгде \textit{pos}~-- это часть речи, $w_i$~--  это похожее слово, $s_i$~-- это значение сходства между $w$ и $w_i$, слова упорядочены по убыванию значения сходства.

Два слова являются \textit{парой взаимных ближайших соседей (RNN} от \textit{respective nearest neighbors)}, если они являются наиболее похожими словами друг для друга (первыми в списке из двухсот слов). С помощью программы удалось получить 543 пары RNN существительных, 212 пар RNN глаголов, 382 пары RNN прилагательных/наречий в созданном автоматически тезаурусе. В табл.~\ref{tabshor} представлен список каждого 10-го RNN для глаголов.

\bfullwidth
\begin{table*}
\centering
\caption{Список пар взаимных ближайших соседей (RNN) глаголов}
\begin{tabular}{|c|l|c|}
\hline
 &  & \\
\textbf{Ранг} & \textbf{RNN} & \textbf{Значение сходства}\\
 &  & \\
\hline
\rule{0pt}{11pt}
  1 & \textit{fall rise} & 0,67\\
\hline
\rule{0pt}{11pt}
11 & \textit{injure kill} & 0,38\\
\hline
\rule{0pt}{11pt}
 21 & \textit{concern worry} & 0,34\\
\hline
\rule{0pt}{11pt}
31 & \textit{convict sentence} & 0,29\\
\hline
\rule{0pt}{11pt}
41 & \textit{limit restrict} & 0,27\\
\hline
\rule{0pt}{11pt}
51 & \textit{narrow widen} & 0,26\\
\hline
\rule{0pt}{11pt}
61 & \textit{attract draw} & 0,24\\
\hline
\rule{0pt}{11pt}
71 & \textit{discourage encourage} & 0,23\\
\hline
\rule{0pt}{11pt}
81 & \textit{hit strike} & 0,22\\
\hline
\rule{0pt}{11pt}
91 & \textit{distregard ignore} & 0,21\\
\hline
\rule{0pt}{11pt}
101 & \textit{overstate understate} & 0,20\\
\hline
\rule{0pt}{11pt}
111 & \textit{affirm reaffirm} & 0,18\\
\hline
\rule{0pt}{11pt}
121 & \textit{inform notify} & 0,17\\
\hline
\rule{0pt}{11pt}
131 & \textit{differ vary} & 0,16\\
\hline
\rule{0pt}{11pt}
141 & \textit{scream yell} & 0,15\\
\hline
\rule{0pt}{11pt}
151 & \textit{laugh smile} & 0,143\\
\hline
\rule{0pt}{11pt}
161 & \textit{compete cope} & 0,136\\
\hline
\rule{0pt}{11pt}
171 & \textit{add whisk} & 0,130\\
\hline
\rule{0pt}{11pt}
181 & \textit{blossom mature} & 0,12\\
\hline
\rule{0pt}{11pt}
191 & \textit{smell taste} & 0,11\\
\hline
\rule{0pt}{11pt}
201 & \textit{bark howl} & 0,10\\
\hline
\rule{0pt}{11pt}
211 & \textit{black white} & 0,07\\
\hline
\end{tabular}
\label{tabshor}
\end{table*}
\efullwidth