%\bfullwidth
\section{WSD на основе нейронных сетей, построенных по данным машиночитаемых словарей}
%\efullwidth
\begin{flushright}
\textit{А. Н. Кириллов}
\end{flushright}

Использование нейронных сетей (NN)  для WSD было предложено в 80-е годы в работах \cite{COTTRELL 1983,WALTZ 1985}. В типичной NN на вход   подается   слово, значение которого требуется установить, т. е. целевое (\textit{target}) слово, а также --- контекст (фраза), его содержащий. Узлы выхода соответствуют различным значениям слова. В процессе обучения, когда значение тренировочного целевого слова известно, веса связующих узлы соединений (связей) настраиваются таким образом, чтобы по окончании обучения выходной узел, соответствующий истинному значению целевого слова, имел наибольшую активность. Веса соединений могут быть  положительными или отрицательными и настраиваются посредством рекуррентных алгоритмов (алгоритм обратного распространения ошибки,  рекуррентный метод наименьших квадратов и т. д.). Сеть может содержать скрытые (hidden) слои, состоящие из узлов, соединенных как прямыми, так и обратными связями. Для представления входной информации обычно используется одна из двух схем:  распределенная (distributed) или локалистская (localist ) (\cite{Azzini},  \cite{COTTRELL 1989}, \cite{Hinton 1986}). 

В работе \cite{VERONIS 1990} описан метод автоматического построения \textbf{\textit{очень больших нейронных сетей}} (VLNN) с помощью текстов, извлекаемых из машиночитаемых словарей (MRD), и рассмотрено использование этих сетей в задачах разрешения лексической неоднозначности. Поясним основную идею VLNN.  Широко известен метод Леска \cite{LESK 1986}  использования  информации  из MRD для  задачи  WSD.  Суть этого метода состоит в вычислении  так называемой \textit{степени пересечения}, т. е. количества общих слов в словарных определениях слов из контекста (<<окна>>) условного размера, содержащего целевое слово. Основной недостаток метода Леска --- зависимость  от  словарной  статьи, т. е. от слов, входящих в нее. Стратегия преодоления  этого  недостатка --- использование словарных статей, определяющих слова, входящие в другие словарные статьи, начиная со словарных статей, соответствующих  словам  из  контекста. Таким образом, образуются  достаточно  длинные   пути  из слов, входящих в словарные статьи. Эта  идея  лежит  в  основе  топологии VLNN. В работе~\cite{VERONIS 1990}  для построения  VLNN использован  словарь  Collins  English  Dictionary.

\textbf{Топология сети.} Целевое слово представлено  узлом, соединенным активирующими  связями со смысловыми узлами, представляющими все возможные значения слова, имеющиеся  в словарных статьях. Каждый смысловой узел, в свою очередь, соединен  активирующими  связями с узлами, представляющими  слова в словарной статье, соответствующей толкованию данного значения. Процесс соединения повторяется многократно, создавая сверхбольшую сеть взаимосвязанных узлов. В идеале сеть может содержать весь словарь. Авторы~\cite{VERONIS 1990}, по практическим соображениям, ограничиваются несколькими тысячами узлов и 10–20 тысячами соединений. Слова представлены своими леммами. 
Узлы, представляющие различные значения слова, соединены запрещающими (inhibitory) связями.  

\textbf{Алгоритм.} При запуске сети первыми активируются узлы входного  слова  (согласно принятой кодировке). Затем  каждый  входной узел посылает активирующий сигнал своим смысловым узлам, с которыми он соединен. В результате  сигналы распространяются по всей сети в течение определенного числа циклов. В каждом цикле узлы слова и  его значений получают обратные сигналы от узлов, соединенных с ними. Узлы конкурирующих значений посылают взаимно подавляющие сигналы.  Взаимодействие  сигналов  обратной  связи  и  подавления,  в соответствии со стратегией <<победитель получает все>>, позволяет увеличить активацию узлов-слов и соответствующих им правильных узлов-значений,  одновременно  уменьшая  активацию  узлов,  соответствующих неправильным значениям. После нескольких десятков  циклов сеть стабилизируется  в  состоянии, в котором активированы  только узлы-значения с наиболее активированными связями  с    узлами-словами. При обучении сети  используется  метод  обратного  распространения (\textit{back  propagation}).